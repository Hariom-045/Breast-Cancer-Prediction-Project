# -*- coding: utf-8 -*-
"""Breat Cancer Prediction Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SfIKMHn4hblPJVMDOuh-xAUN-n2_p77w
"""

#importing libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

#UPLOADING THE DATASET
from google.colab import files
uploaded = files.upload()
df = pd.read_csv('data.csv')

df.head(10)

#DATASET SHAPE
df.shape

#Columnwise null or nan or NaN values in dataset
df.isna().sum()

#dropping the column having all null values
df=df.dropna(axis=1)

df.head(3)
df.shape

#GET THE COUNT OF MALIGNANT(cancerous) AND BENIGN(non cancerous) CANCER CELLS
df['diagnosis'].value_counts()

#VISUALIZING THE COUNT OF MALIGNANT AND BENIGN CANCER CELLS
sns.countplot(df['diagnosis'],label='Count')

#LOOKING FOR THE COLUMNS WHICH NEEDS TO BE ENCODDED BY CHECKING THEIR DATATYPE
df.dtypes

#Encoding the diagnosis column from object to int
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df.iloc[:,1] = le.fit_transform(df.iloc[:,1].values)

df.head()

#creating a pair plot
sns.pairplot(df.iloc[:,1:6],hue='diagnosis')

#visualization the correlation of colums
plt.figure(figsize=(10,10))
sns.heatmap(df.iloc[:,1:12].corr(),annot=True,fmt='.0%')

#SPLITTING THE DATASET INTO INDEPENDENT AND DEPENDENT DATA
x=df.iloc[:,2:31].values
y=df.iloc[:,1].values

x.shape

y.shape

y

#SPLITTING THE DATA INTO TRAINING AND TESTING DATA
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state = 0)

#SCALING THE DATA WITH THE HELP OF STANDARD SCALER
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.fit_transform(x_test)

#MAKING THE MODELS

#LOGISTIC REGRESSION
from sklearn.linear_model import LogisticRegression
log = LogisticRegression(random_state = 0)
log.fit(x_train,y_train)

#DECISION TREE 
from sklearn.tree import DecisionTreeClassifier
tree = DecisionTreeClassifier(criterion='entropy',random_state=0)
tree.fit(x_train,y_train)

from sklearn.svm import SVC
svc = SVC(kernel='linear',random_state = 0)
svc.fit(x_train,y_train)

#RANDOM FOREST CLASSIFIER
from sklearn.ensemble import RandomForestClassifier
forest = RandomForestClassifier(n_estimators=10,criterion='entropy',random_state=0)
forest.fit(x_train,y_train)

#GETTING SCORE ON TRAINING DATA BY ALL THE MODELS
print('SCORE OF ALL MODELES ON TRAINING DATA\n')
print("Score of Logistic regression is :",log.score(x_train,y_train))
print("Score of decision tree is :",tree.score(x_train,y_train))
print("Score of SVM model is :",svc.score(x_train,y_train))
print("Score of Random forest Classifier is :",forest.score(x_train,y_train))

#PREDICTING THE TEST SET RESULTS OF ALL MODELS
log_pred = log.predict(x_test)
tree_pred= tree.predict(x_test)
svc_pred = svc.predict(x_test)
forest_pred=forest.predict(x_test)

#GETTING ACCURACY SCORES ON TEST DATA OF ALL MODELS
from sklearn.metrics import accuracy_score
print('Accuracy Score of logistic Regression on test data:',accuracy_score(log_pred,y_test))
print('Accuracy Score of decision tree on test data:',accuracy_score(tree_pred,y_test))
print('Accuracy Score of support vector machine on test data:',accuracy_score(svc_pred,y_test))
print('Accuracy Score of Random Forest Classifier on test data:',accuracy_score(forest_pred,y_test))

#HENCE BY COMPARING ALL SCORES RANDOM FOREST PERFORMED BEST.